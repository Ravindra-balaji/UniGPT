# -*- coding: utf-8 -*-
"""UniGPTModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_0v2WEhn7Rvm5iMjrPNYmOkMN6f4c28C
"""

!pip install langchain                # Core
!pip install langchain-community      # Community loaders & tools (PyPDFLoader etc.)
!pip install langchain-qdrant         # Qdrant integration
!pip install langchain-huggingface    # HuggingFace embeddings
!pip install langchain-cohere

!pip install pypdf

!pip install qdrant-client

!pip install sentence-transformers

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_qdrant import QdrantVectorStore
from langchain_huggingface import HuggingFaceEmbeddings

from langchain_core.prompts import ChatPromptTemplate

from langchain_cohere import ChatCohere

from qdrant_client import QdrantClient
from qdrant_client.http.models import Distance, VectorParams

from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain

from langchain_community.document_loaders import PyPDFLoader

from sentence_transformers import SentenceTransformer

import pandas as pd

loader = PyPDFLoader("/content/Dress Code and Uniform Policy for Students.pdf")

docs = loader.load()

docs

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)
chunks = text_splitter.split_documents(docs)

model_name="sentence-transformers/all-mpnet-base-v2"
#model_name="BAAI/bge-large-en-v1.5"
#model_name="nomic-ai/nomic-embed-text-v1.5"

encode_kwargs = {'normalize_embeddings': False}
embeddings = HuggingFaceEmbeddings(model_name=model_name,encode_kwargs=encode_kwargs)

path_name = "../tmp/langchain_qdrant3"
#path_name = "../embeddings/nomic_ai"

collection_name = "my_data1"  #should be renamed if we have to use or run again

client = QdrantClient(path=path_name)  #should be run only once

client.create_collection(
    collection_name=collection_name,
    vectors_config=VectorParams(size=768, distance=Distance.COSINE),
)

vector_store = QdrantVectorStore(
    client=client,
    collection_name=collection_name,
    embedding=embeddings,
)

vector_store.add_documents(documents=chunks)

model = SentenceTransformer("sentence-transformers/all-mpnet-base-v2")

print(client.get_collections())

retriever = vector_store.as_retriever(search_type='mmr',
                          search_kwargs={'k':2}
                         )

user_query = "Shirt"

retrieval = retriever.get_relevant_documents(user_query)

retriever.invoke(user_query)

llm = ChatCohere(
    model="command-a-03-2025",
    temperature=0.3,
    max_tokens=300,
    cohere_api_key="dRrV13nDT200p0mV7g3hKyBfmgIAf2YWxspzO4cl"
)

llm.invoke('hey')

prompt = ChatPromptTemplate.from_template("""You are an assistant that answers students' questions about university details, rules, and guidelines.
Always use the provided context to answer.
If the answer is found in the context, give a clean, concise, and clear response in 3â€“5 sentences.
Do not add information outside the context.
If the context does not contain the answer, say:
"I'm sorry, I could not find that information in the university guidelines."



Answer the following question based only on the provided context:

<context>
{context}
</context>

Question: {input}""")

document_chain = create_stuff_documents_chain(llm, prompt)

retrieval_chain = create_retrieval_chain(retriever, document_chain)

user_query = "Today is my first day of college , suggest me the outfit to university"

response = retrieval_chain.invoke({"input": user_query})

print(response["answer"])

